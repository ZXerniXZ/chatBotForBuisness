# Ollama Bot - Basic Chat Interface

Bot semplice per interagire con modelli Ollama locali, pronto per implementazione MCP client.

## ğŸš€ Avvio rapido

```bash
# Metodo automatico
./run_bot.sh

# Metodo manuale
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python3 ollama_bot.py
```

## ğŸ“‹ Prerequisiti

1. **Ollama** installato e in esecuzione
2. **Modello Llama3** scaricato: `ollama pull llama3:8b`

## âš™ï¸ Configurazione

Variabili d'ambiente:
- `OLLAMA_MODEL`: Modello da usare (default: `llama3:8b`)
- `OLLAMA_URL`: URL server Ollama (default: `http://localhost:11434`)

## ğŸ’¬ Comandi

- `quit`, `exit`, `q`: Uscire
- `reset`: Reset cronologia
- `stats`: Statistiche sessione

## ğŸ”„ Per MCP Client

Il codice Ã¨ strutturato per facilitare l'implementazione MCP:
- Classe `OllamaBot` modulare
- Gestione stato giÃ  implementata
- Metodi indipendenti e riutilizzabili

## ğŸ› Troubleshooting

```bash
# Verificare Ollama
ollama serve
curl http://localhost:11434/api/tags

# Scaricare modello
ollama pull llama3:8b
``` 